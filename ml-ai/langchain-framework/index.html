<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>langchain 프레임워크</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="stylesheet" href="/assets/css/study.css">
    <link rel="stylesheet" href="/assets/css/sidebar.css">
    <link rel="stylesheet" href="/assets/css/header.css">
    <link rel="stylesheet" href="/assets/css/banner.css">
    <link rel="stylesheet" href="/assets/css/sections.css">
    <link rel="stylesheet" href="/assets/css/post.css">
    <link rel="stylesheet" href="/assets/css/categories.css">
    <link rel="stylesheet" href="/assets/css/projects.css">
</head>
<body>
    <div class="container">
        <!-- 사이드바 -->
        <aside class="sidebar">
    <img src="/assets/images/avatar.png" alt="Duri" class="profile-image">
    <div class="profile-info">
        <h2>Duri</h2>
        <p>˗ˏˋ ⋆｡𖦹 ˚ 𓇼 ˚｡⋆ ❀˖°</p>
        <p>옛날에 
 데이터 엔지니어가 있엇슨.. 백엔드 서버도 만들고 인프라도 구축하고 데이터 분석도 했슨.. </p>
    </div>
    
    <div class="contact-links">
        <div class="profile-divider">
    ⠀⠀⠀⠀⠀⠀⢀⡤⣤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⡀⠀⠀⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⢀⡏⠀⠀⠈⠳⣄⠀⠀⠀⠀⠀⣀⠴⠋⠉⠉⡆⠀⠀⠀⠀⠀
    ⠀⠀⠀⠀⠀⢸⠀⠀⠀⠀⠀⠈⠉⠉⠙⠓⠚⠁⠀⠀⠀⠀⣿⠀⠀⠀⠀⠀
    ⠀⠀⠀⠀⢀⠞⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣄⠀⠀⠀⠀
    ⠀⠀⠀⠀⡞⠀⠀⠀⠀⠀⠶⠀⠀⠀⠀⠀⠀⠦⠀⠀⠀⠀⠀⠸⡆⠀⠀⠀
    ⢠⣤⣶⣾⣧⣤⣤⣀⡀⠀⠀⠀⠀⠈⠀⠀⠀⢀⡤⠴⠶⠤⢤⡀⣧⣀⣀⠀
    ⠻⠶⣾⠁⠀⠀⠀⠀⠙⣆⠀⠀⠀⠀⠀⠀⣰⠋⠀⠀⠀⠀⠀⢹⣿⣭⣽⠇
    ⠀⠀⠙⠤⠴⢤⡤⠤⠤⠋⠉⠉⠉⠉⠉⠉⠉⠳⠖⠦⠤⠶⠦⠞⠁⠀⠀⠀
        </div>
        
        <a href="https://github.com/duri-wip" class="contact-link" target="_blank">
            <i class="fab fa-github"></i>
            <span>GitHub</span>
        </a>
        
        
        <a href="mailto:8s.eow.ooc@gmail.com" class="contact-link">
            <i class="fas fa-envelope"></i>
            <span>Email</span>
        </a>
        
    </div>
    
</aside>
        
        <!-- 메인 콘텐츠 -->
        <main class="main-content">
            <!-- 헤더 -->
            <header class="header">
    <nav>
        <ul class="nav-menu">
            <li class="nav-item">
                <a href="/">home</a>
            </li>
            <li class="nav-item">
                <a href="/categories">category</a>
            </li>
            <li class="nav-item">
                <a href="/study">study</a>
            </li>
            <li class="nav-item">
                <a href="/projects">project</a>
            </li>
        </ul>
    </nav>
</header>
            
            <!-- 콘텐츠 영역 -->
            <div class="content">
                <article class="post">
    <header class="post-header">
        <h1 class="post-title">langchain 프레임워크</h1>
        <div class="post-meta">
            <time class="post-date">2025년 07월 02일</time>
            
            <div class="post-categories">
                
                    
                    <span class="category-tag">ML-AI</span>
                    
                
                    
                
                
                <span class="subcategory-tag">llm</span>
                
            </div>
            
            
            <div class="post-tags">
                
                <span class="tag">#genai</span>
                
                <span class="tag">#llm</span>
                
                <span class="tag">#study</span>
                
                <span class="tag">#langchain</span>
                
                <span class="tag">#study-llm-framework</span>
                
            </div>
            
        </div>
    </header>

    <div class="post-content">
        <h1 id="개요">개요</h1>
<p>랭체인만 사용하는 경우는 거의 없지만 이 프레임워크에 대해서 이해한 것을 기반으로 다른 프레임워크를 능숙하게 사용할 수 있도록 하는게 중요하다.</p>

<h2 id="패키지-그룹-소개">패키지 그룹 소개</h2>
<ol>
  <li>core :  추상화와 LCEL을 제공한다.</li>
  <li>partners: 언어 모델 통합 클래스를 제공함.</li>
  <li>community: partners에서 제공하지 않는 모델을 제공. langchain-text-splitters, langchain-experimental 청킹 등 다양한 실험 기능을 제공함</li>
</ol>

<h2 id="설치">설치</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>!pip install langchain-core langchain-openai pydantic
</code></pre></div></div>

<h1 id="사용방법">사용방법</h1>

<h2 id="1-싱글턴-질의-보내기">1. 싱글턴 질의 보내기</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_openai import OpenAI

model = OpenAI(model = "gpt-3.5-turbo-instruct", temperature = 0.0, api_key = "api_key")
output = model.invoke("Hello, world!")
print(output)
</code></pre></div></div>

<ul>
  <li>랭체인 프레임워크를 쓰면, 사용할 언어 모델 패키지가 제공하는 api 호출 방법에 구속되지 않고 싱글턴 질의를 보낼 수 있다.</li>
  <li>사용하고 싶은 언어 모델의 프레임워크 또는 패키지에 대한 공부 없이도 모델을 사용할 수 있게 된다.</li>
</ul>

<h2 id="2-대화내용을-컨텍스트로-함께-보내기">2. 대화내용을 컨텍스트로 함께 보내기</h2>

<p>ChatOpenAI를 사용하면 이렇게 구성할 수 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model = "gpt-4o-mini", temperature = 0.0, api_key = "api_key")

messages = [
    SystemMessage(content = "당신은 사용자에게 음식의 레시피를 알려주는 요리사입니다. 조리 순서와 방법을 알려주세요."),
    HumanMessage(content = "치즈 요리를 먹고 싶습니다."),
    AIMessage(content = "어떤 치즈 요리를 좋아하시나요?"),
    HumanMessage(content = "치즈 퐁듀 레시피를 알려주세요.")
]

ai_message = model.invoke(messages)
print(ai_message.content)
</code></pre></div></div>

<h3 id="chatopenai-vs-openai">ChatOpenAI vs OpenAI</h3>
<p>컨텍스트를 함께 포함하는 방식에 관해서 openai 는 두개의 방법을 사용할 수 있다.</p>

<ul>
  <li>OpenAI는 단순 텍스트 입력만 가능하지만, ChatOpenAI는 대화 내용을 함께 보낼 수 있음</li>
  <li>OpenAI는 단일 질의에 적합하고, ChatOpenAI는 대화형 상호작용에 적합함</li>
  <li>OpenAI는 gpt-3.5-turbo-instruct 같은 명령어 기반 모델을, ChatOpenAI는 gpt-4 같은 채팅 기반 모델을 사용</li>
  <li>ChatOpenAI는 SystemMessage로 AI의 역할을 지정할 수 있음</li>
</ul>

<h2 id="3-prompt-template-사용하기">3. prompt template 사용하기</h2>

<p>시스템 템플릿을 주는 방법이 표준화 된다.
랭체인 없이 사용할 모델의 별도 프레임워크를 사용하는 경우에는 시스템 프롬프트를 주는 방식이 각양 각색이다. 이런 위험을 회피하고 쓰는 사람도, 읽는 사람도 알기 쉽게 코드를 작성할 수 있다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that can answer questions."),
    ("human", "{input}")
])
</code></pre></div></div>

<h2 id="4-message-holder--메시지가-들어가는-플레이스-홀더-넣기">4. message holder : 메시지가 들어가는 플레이스 홀더 넣기</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that can answer questions."),
    MessagesPlaceholder("chat_history", optional=True),
    ("human", "{input}")
])

prompt_value = prompt.invoke({
    "chat_history": [
        HumanMessage(content = "What is the capital of France?"),
        AIMessage(content = "The capital of France is Paris.")
    ],
    "input": "What is the capital of Germany?"
})

print(prompt_value)
</code></pre></div></div>

<p>기초적인 수준이지만, 이런 기능을 제공하는 것도 편의성에 많은 영향을 준다. 
llm으로 가장 많이 만들어야하는 기능이 사용자와 상호작용하는 front 부분인데, 여기에는 필연적으로 사용자의 메시지와 ai의 메시지가 표출되어야한다. 랭체인 프레임워크에서 이런 기능을 제공해줌으로써 개발자가 이 메시지들을 따로 태깅하고 관리할 필요가 줄어든다.</p>

<h2 id="5-멀티-모달-기능">5. 멀티 모달 기능</h2>

<p>대부분 멀티미디어(사진, 음성, 영상 등)을 컨텍스트로 사용해서 응답을 받기 위해서는 모델에 종속적으로 작업해야한다. 어떤 모델은 되고, 어떤 모델은 안되는 경우가 많기 때문이다. 또 같은 이미지더라도 확장자에 따라서 읽을 수 없는 경우도 있고 .. 다양하다. 이런 상황에서 발생하는 에러를 회피하기 위해서는 사용하고 있는 모델의 사용 범위를 잘 알고 있어야 한다.</p>

<p>랭체인에서도 이런 방식으로 멀티 모달 기능을 제공하고 있다.</p>

<p>근데 아마도 모델마다 되는게 있을테니 확인은 필요하다. 그럼에도 불구하고 표준화된 방식으로 미디어를 태울 수 있다는 점은 큰 장점이다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_core.prompts import ChatPromptTemplate
import base64

def encode_image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

prompt = ChatPromptTemplate.from_messages([
    (
        "user",
        [
            {"type": "text", "text": "{input}"},
            {"type": "image_url", "image_url": {"url": "{url_input}"}},
            {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,{local_image}"}}
        ]
    )
])

# URL 이미지 사용
url_prompt_value = prompt.invoke({
    "input": "What is the capital of France?", 
    "url_input": "https://i.imgur.com/ZcQmbtY.jpg",
    "local_image": ""
})
print("URL 이미지 결과:")
print(url_prompt_value)

# 로컬 이미지 사용
local_image_path = "path/to/your/local/image.jpg"
base64_image = encode_image_to_base64(local_image_path)
local_prompt_value = prompt.invoke({
    "input": "What is the capital of France?",
    "url_input": "",
    "local_image": base64_image
})
print("\n로컬 이미지 결과:")
print(local_prompt_value)
</code></pre></div></div>

    </div>

    <footer class="post-footer">
        <div class="post-nav">
            
            <a class="prev-post" href="/dataengineering/spark-newproject3/">
                <span class="nav-label">이전 글</span>
                <span class="nav-title">Spark 클러스터 구축하기3</span>
            </a>
            
            
            
            <a class="next-post" href="/ml-ai/output-parse/">
                <span class="nav-label">다음 글</span>
                <span class="nav-title">LangChain Output Parser</span>
            </a>
            
        </div>
        
        <div class="back-to-home">
            <a href="/">← 홈으로 돌아가기</a>
        </div>
    </footer>
</article>
            </div>
        </main>
    </div>
</body>
</html>